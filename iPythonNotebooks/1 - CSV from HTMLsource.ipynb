{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Scraping website for information about libraries"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For getting information about the libraries, the database of the German Library Statistics (Deutsche Bibliotheksstatistik/DBS) which is hosted by the HBZ was used:\n",
      "\n",
      "http://www.bibliotheksstatistik.de/eingabe/dynrep/adrbrowser/bibs.php\n",
      "\n",
      "For this project, 4 different requests were made:\n",
      "\n",
      "1. DBS National Libraries   ( == > 3 active<sup>(1)</sup> libraries)\n",
      "1. DBS Section 4: University Libraries (i.e. not the entire Section 4 was queried) ( == > 83 active<sup>(2)</sup> libraries)\n",
      "1. DBS Section 1: Public Libraries with population > 400,000 ( == > 18 libraries)<sup>(3)</sup>\n",
      "1. DBS Section 2: Public Libraries with population > 100,000 ( == > 81 libraries)<sup>(4)</sup>\n",
      "\n",
      "Since the website doesn't give unique URLs for individual requests, \n",
      "you could download the source code of each database request and safe as html files.\n",
      "\n",
      "However, you could use the _printing page_ of the database result list, which returns\n",
      "an individual URL. This procedure is followed here, with the URLs given in the list of tuples \"urlList\".\n",
      "\n",
      "The result will be saved as a csv file for each database request to the cwd (i.e. current working directory).<sup>(5)</sup>\n",
      "Furthermore, those libraries without a valid url will be printed out (in a JSON prettyprint style).\n",
      "\n",
      "---\n",
      "\n",
      "<sup>(1)</sup> In DBS National Libraries, there are actually four libraries listed, but one is inactive.\n",
      "\n",
      "<sup>(2)</sup> In DBS Section 4: University Libraries, there are actually 84 libraries listed, but one is inactive.\n",
      "\n",
      "<sup>(3)</sup> Two libraries were added manually to this goup of libraries: The Hamburger B\u00fccherhallen, whose  entry in DBS omitted the DBV Section, and the Zentral- und Landesbibliothek Berlin, which was listed as member of Section 4 \"Wissenschaftliche Universalbibliotheken\", though the library is member of Section 1 (and only guest member of Section 4 according to the DBV webpage (http://www.bibliotheksverband.de/mitglieder/).\n",
      "\n",
      "<sup>(4)</sup> From DBS Section 2, two libraries (KA119 and KA129) were removed: These are small \"ehrenamtlich gef\u00fchrte\" libraries (less than 1,000 books) without any presence on the internet.\n",
      "For two more libraries (MB026 and GY440) the urls, missing in the DBS, were added manually.\n",
      "\n",
      "<sup>(5)</sup> To find out, what your cwd is, type:\n",
      "\n",
      ">```import os\n",
      ">print os.getcwd()```\n",
      "\n",
      "---\n",
      "\n",
      "Data was collected: 2014-02-08\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "List of URLs"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# List of tuples of name & url\n",
      "# urlList[0] = Nr. 1 (DBS National Libraries)\n",
      "# urlList[1] = Nr. 2 (DBS Section 4, University Libraries)\n",
      "# urlList[2] = Nr. 3 (DBS Section 1)\n",
      "# urlList[3] = Nr. 4 (DBS Section 2)\n",
      "\n",
      "\n",
      "urlList = [('DBS_NatBib', 'http://www.bibliotheksstatistik.de/eingabe/dynrep/adrbrowser/adrbrowser.php?prt=AG012|AG292|AG000|AK001'),\n",
      "           ('DBS_4_UB', 'http://www.bibliotheksstatistik.de/eingabe/dynrep/adrbrowser/adrbrowser.php?prt=EM482|AH715|EJ882|EX035|AA708|AG188|DB900|DE081|AD011|DB079|AF093|AH090|AA289|MM201|AF007|EL283|AJ082|AB294|AD291|AE088|AX001|AA046|AC018|AB105|AA083|EL131|AE830|AL091|AE027|BK213|AX566|AL352|AK517|EX461|AL005|AL017|AG061|AC006|AE003|AB038|AK384|AD473|AH703|AB361|AD084|AK104|AF020|AA290|DE100|SB005|AL029|AK025|AB026|AA009|AH089|AH016|AN087|AJ100|EL039|AC030|AE386|AA034|AJ008|BD987|AE015|BD296|AH077|AE180|AH004|AF019|AK700|AH466|AH739|AJ355|AH028|AL467|AB385|AJ021|BZ398|AC468|DC072|DA385|BE926|FH880'),\n",
      "           ('DBS_1', 'http://www.bibliotheksstatistik.de/eingabe/dynrep/adrbrowser/adrbrowser.php?prt=AJ197|GE486|AA381|AE131|AH478|AJ136|AE064|AK062|AG115|AB075|AJ380|AL480|AH132|AA277|AE362|AE106'),\n",
      "           ('DBS_2', 'http://www.bibliotheksstatistik.de/eingabe/dynrep/adrbrowser/adrbrowser.php?prt=AF111|MB026|GB291|AH259|GC556|KA119|KA129|GD895|AJ367|AF238|AD242|AD072|AG243|GY440|AA186|AB063|AH181|AD369|AC134|AF135|GE231|KS124|AL285|AF196|KQ152|AK116|AG279|AE295|AD217|GD822|AK153|GM675|AG267|AK293|AC286|AB178|AF275|AJ033|AL157|AC122|AJ471|WB861|LD510|GC283|AD059|MB038|AA174|AG371|AG231|LC499|LC505|AJ069|AG073|GB850|WB782|MB014|AH260|AH168|GC301|AJ264|GD998|GE012|GE036|MB002|GD767|AD163|AH351|AC262|GA444|GE462|GB746|AA472|GE899|AH247|AA447|AB270|GE164|GA596|AH284|AF470|AB142|AD229|JA868')]\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Functions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from bs4 import BeautifulSoup\n",
      "import urllib2\n",
      "import json\n",
      "import csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def writeDict(bsString):\n",
      "    \n",
      "    s = bsString.lstrip()   # stripping off leading whitespace\n",
      "    i1 = s.find(\"(DBS-ID: \")\n",
      "    i2 = i1 + len(\"(DBS-ID: \")\n",
      "    i3 = s.find(\", Sig.\")   # if there is no Sig. given, i3 returns -1 [i.e. the closing paren \")\"]\n",
      "    name = s[:i1-1]\n",
      "    i4 = name.find(' ')   # to get the place, split name at first white space\n",
      "    dbsID = s[i2:i3]\n",
      "    place = name[:i4]\n",
      "    dic = {}\n",
      "    dic['DBS-ID'] = dbsID.encode(\"utf-8\")   # BeautifulSoup encodes in Unicode,\n",
      "    dic['Name'] = name.encode(\"utf-8\")      # which is not supported by csv;\n",
      "    dic['Ort'] = place.encode(\"utf-8\")      # hence encoding to utf-8 is necessary\n",
      "    dic['Twitter'] = ''\n",
      "    return dic\n",
      "\n",
      "def findURL(soupTAG):\n",
      "    urlTAG = soupTAG.find_next(\"a\")\n",
      "    url = urlTAG.get('href')\n",
      "    d = {}\n",
      "    d['URL'] = url.encode(\"utf-8\")\n",
      "    return d\n",
      "\n",
      "def parseHTML(soupHTML):\n",
      "    \n",
      "    l = []\n",
      "    loD = []\n",
      "    s0 = soupHTML.table.table.h3\n",
      "    while type(s0) != type(None):    # first write each entry which is not NoneType to a list\n",
      "        l.append(s0)\n",
      "        s_next = s0.find_next(\"h3\")\n",
      "        s0 = s_next\n",
      "        \n",
      "    for i in l:                           \n",
      "        url = findURL(i)             # finding the next url for each entry        \n",
      "        si = i.string                # second write each string of the list which is not NoneType  \n",
      "        if type(si) != type(None):   # to a List of Dictionaries\n",
      "            di = writeDict(si)\n",
      "            di.update(url)           # adding the url to the dict\n",
      "            loD.append(di)\n",
      "        else:\n",
      "            pass\n",
      "    return loD\n",
      "\n",
      "\n",
      "def libCSV(index_of_urlList):\n",
      "    '''\n",
      "    pass as argument the index number of the urlList\n",
      "    prints out \n",
      "    (1.) Nr. of (active) libraries in the list\n",
      "    (2.) A JSON prettyprint list of libraries without a valid url\n",
      "    (3.) The name of the csv file.\n",
      "    Saves the csv file in the cwd.\n",
      "    \n",
      "    '''\n",
      "    tup = urlList[index_of_urlList]\n",
      "    u = tup[1]\n",
      "    web = urllib2.urlopen(u)\n",
      "    webHTML = web.read()\n",
      "    web.close()\n",
      "    soup = BeautifulSoup(webHTML)\n",
      "    \n",
      "    result = parseHTML(soup)\n",
      "    print 'For', tup[0], len(result), '(active) libraries could be found.'\n",
      "    for i in result:\n",
      "        if i[\"URL\"] == \"\":\n",
      "            print 'For this library no URL could be found: \\n'\n",
      "            print json.dumps(i, indent=1), '\\n'\n",
      "            \n",
      "    filename = tup[0] + '.csv'\n",
      "    l1 = len(filename) + len('The csv will be safed as ')\n",
      "    print \"\\n\"+ l1*\"=\" + \"\\n\"\n",
      "    print 'The csv will be safed as', filename\n",
      "    return exp2CSV(result, filename)\n",
      "\n",
      "\n",
      "def exp2CSV(listOfDict, filename):\n",
      "    '''\n",
      "    arguments = list of dictionaries, filename\n",
      "    output = saves file to cwd (current working directory)\n",
      "    '''\n",
      "    outputfile = filename\n",
      "    keyz = listOfDict[0].keys()\n",
      "    f = open(outputfile,'w')\n",
      "    dict_writer = csv.DictWriter(f,keyz)\n",
      "    dict_writer.writer.writerow(keyz)\n",
      "    dict_writer.writerows(listOfDict)\n",
      "    f.close()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Function call for each group of libraries"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# pass in the index nr. of the urlList!\n",
      "libCSV(0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "For DBS_NatBib 3 (active) libraries could be found.\n",
        "\n",
        "=======================================\n",
        "\n",
        "The csv will be safed as DBS_NatBib.csv\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# pass in the index nr. of the urlList!\n",
      "libCSV(1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "For DBS_4_UB 83 (active) libraries could be found.\n",
        "For this library no URL could be found: \n",
        "\n",
        "{\n",
        " \"URL\": \"\", \n",
        " \"Ort\": \"Koblenz-Landau\", \n",
        " \"DBS-ID\": \"BD987\", \n",
        " \"Name\": \"Koblenz-Landau UB\", \n",
        " \"Twitter\": \"\"\n",
        "} \n",
        "\n",
        "\n",
        "=====================================\n",
        "\n",
        "The csv will be safed as DBS_4_UB.csv\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# pass in the index nr. of the urlList!\n",
      "libCSV(2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "For DBS_1 16 (active) libraries could be found.\n",
        "\n",
        "==================================\n",
        "\n",
        "The csv will be safed as DBS_1.csv\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# pass in the index nr. of the urlList!\n",
      "libCSV(3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "For DBS_2 83 (active) libraries could be found.\n",
        "For this library no URL could be found: \n",
        "\n",
        "{\n",
        " \"URL\": \"\", \n",
        " \"Ort\": \"Berlin\", \n",
        " \"DBS-ID\": \"MB026\", \n",
        " \"Name\": \"Berlin Pankow StB\", \n",
        " \"Twitter\": \"\"\n",
        "} \n",
        "\n",
        "For this library no URL could be found: \n",
        "\n",
        "{\n",
        " \"URL\": \"\", \n",
        " \"Ort\": \"Kassel\", \n",
        " \"DBS-ID\": \"KA119\", \n",
        " \"Name\": \"Kassel KuJB\", \n",
        " \"Twitter\": \"\"\n",
        "} \n",
        "\n",
        "For this library no URL could be found: \n",
        "\n",
        "{\n",
        " \"URL\": \"\", \n",
        " \"Ort\": \"Kassel\", \n",
        " \"DBS-ID\": \"KA129\", \n",
        " \"Name\": \"Kassel KuJB\", \n",
        " \"Twitter\": \"\"\n",
        "} \n",
        "\n",
        "For this library no URL could be found: \n",
        "\n",
        "{\n",
        " \"URL\": \"\", \n",
        " \"Ort\": \"Mainz\", \n",
        " \"DBS-ID\": \"GY440\", \n",
        " \"Name\": \"Mainz StB\", \n",
        " \"Twitter\": \"\"\n",
        "} \n",
        "\n",
        "\n",
        "==================================\n",
        "\n",
        "The csv will be safed as DBS_2.csv\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Output of the function calls"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For archival reasons, the output of the function calls is saved here as text:"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "[0]\n",
      "\n",
      "For DBS_NatBib 3 (active) libraries could be found.\n",
      "\n",
      "=======================================\n",
      "\n",
      "The csv will be safed as DBS_NatBib.csv\n",
      "\n",
      "\n",
      "[1]\n",
      "\n",
      "For DBS_4_UB 83 (active) libraries could be found.\n",
      "For this library no URL could be found: \n",
      "\n",
      "{\n",
      " \"URL\": \"\", \n",
      " \"Ort\": \"Koblenz-Landau\", \n",
      " \"DBS-ID\": \"BD987\", \n",
      " \"Name\": \"Koblenz-Landau UB\", \n",
      " \"Twitter\": \"\"\n",
      "} \n",
      "\n",
      "\n",
      "=====================================\n",
      "\n",
      "The csv will be safed as DBS_4_UB.csv\n",
      "\n",
      "\n",
      "[2]\n",
      "\n",
      "For DBS_1 16 (active) libraries could be found.\n",
      "\n",
      "==================================\n",
      "\n",
      "The csv will be safed as DBS_1.csv\n",
      "\n",
      "\n",
      "[3]\n",
      "\n",
      "For DBS_2 83 (active) libraries could be found.\n",
      "For this library no URL could be found: \n",
      "\n",
      "{\n",
      " \"URL\": \"\", \n",
      " \"Ort\": \"Berlin\", \n",
      " \"DBS-ID\": \"MB026\", \n",
      " \"Name\": \"Berlin Pankow StB\", \n",
      " \"Twitter\": \"\"\n",
      "} \n",
      "\n",
      "For this library no URL could be found: \n",
      "\n",
      "{\n",
      " \"URL\": \"\", \n",
      " \"Ort\": \"Kassel\", \n",
      " \"DBS-ID\": \"KA119\", \n",
      " \"Name\": \"Kassel KuJB\", \n",
      " \"Twitter\": \"\"\n",
      "} \n",
      "\n",
      "For this library no URL could be found: \n",
      "\n",
      "{\n",
      " \"URL\": \"\", \n",
      " \"Ort\": \"Kassel\", \n",
      " \"DBS-ID\": \"KA129\", \n",
      " \"Name\": \"Kassel KuJB\", \n",
      " \"Twitter\": \"\"\n",
      "} \n",
      "\n",
      "For this library no URL could be found: \n",
      "\n",
      "{\n",
      " \"URL\": \"\", \n",
      " \"Ort\": \"Mainz\", \n",
      " \"DBS-ID\": \"GY440\", \n",
      " \"Name\": \"Mainz StB\", \n",
      " \"Twitter\": \"\"\n",
      "} \n",
      "\n",
      "\n",
      "==================================\n",
      "\n",
      "The csv will be safed as DBS_2.csv"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}