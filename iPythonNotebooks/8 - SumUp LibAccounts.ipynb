{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Sum up the LibAccount Stats"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this Notebook, the statistics of the library accounts is being summarized. The `libTwitterStats`-function takes as arguments \n",
      "\n",
      "   1. the basicStats-file from Notebook 4,\n",
      "   1. the network-file from Notebook 5.0,\n",
      "   1. the friends- and followers-files from Notebook 5.1, and\n",
      "   1. the timeLineStats-file from Notebook 7.1\n",
      "   \n",
      "The file will be saved as NatBib_libTwitterStats_2014-04-09.csv etc.\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Function Definitions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "\n",
      "def impCSV(input_file):\n",
      "    '''\n",
      "    input_file = csv with keys: \"URL\", \"Twitter\"\n",
      "    output = list of dictionaries\n",
      "    '''\n",
      "    f = open(input_file, 'r')\n",
      "    d = csv.DictReader(f)\n",
      "    LoD = []   # list of dictionaries\n",
      "    for row in d:\n",
      "        LoD.append(row)\n",
      "    f.close()\n",
      "    return LoD\n",
      "    \n",
      "    \n",
      "def exp2CSV(listOfDict, filename):\n",
      "    '''\n",
      "    arguments = list of dictionaries, filename\n",
      "    output = saves file to cwd (current working directory)\n",
      "    '''\n",
      "    keyz = listOfDict[0].keys()\n",
      "    f = open(filename,'w')\n",
      "    dict_writer = csv.DictWriter(f,keyz)\n",
      "    dict_writer.writer.writerow(keyz)\n",
      "    dict_writer.writerows(listOfDict)\n",
      "    f.close()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def libTwitterStats(basicStatsFile, NetWork_datestamp, Friends_datestamp, timelineStats_datestamp):\n",
      "    # 1. NatBib_BasicStats_2014-03-24.csv\n",
      "    # all keys\n",
      "    filename = basicStatsFile\n",
      "    datestampNW = NetWork_datestamp               # datestamp of Networkfile\n",
      "    datestampFriends = Friends_datestamp\n",
      "    datestampTLS = timelineStats_datestamp\n",
      "    LoD = []\n",
      "    bs = impCSV(filename)\n",
      "    print 'Number of libraries:', len(bs)\n",
      "    \n",
      "    # 2. open corresponding Network file for each library\n",
      "    for e in bs:\n",
      "        sn = e['screen_name']\n",
      "        nwfn = sn + '_NetWork_' + datestampNW + '.csv'\n",
      "        tweets = int(e['statuses_count'])\n",
      "        nwdic = impCSV(nwfn)[0]\n",
      "        nwdic.pop('screen_name', None)\n",
      "        nwdic.pop('libLocation', None)\n",
      "        nwdic.pop('followBack', None)\n",
      "        nwdic.pop('followers_ids', None)\n",
      "        nwdic.pop('friends_ids', None)\n",
      "        e.update(nwdic)                        # update the dictionary e\n",
      "     \n",
      "        # 3. friends file offnen\n",
      "        friendsFileName = sn + '_Friends_' + datestampFriends + '.csv'\n",
      "        \n",
      "        try:      \n",
      "            friends = impCSV(friendsFileName)\n",
      "            friendsDic = {}\n",
      "            from collections import Counter\n",
      "            LoCluster = []\n",
      "            LoLocation = []\n",
      "            for i in friends:\n",
      "                LoCluster.append(i['cluster'])\n",
      "                LoLocation.append(i['friends_location'])\n",
      "            cluster = Counter(LoCluster)  \n",
      "            location = Counter(LoLocation)\n",
      "        except:\n",
      "            friendsDic = {'friend_librarian': 'NA', 'friend_library': 'NA', 'friend_publisher': 'NA',\n",
      "                          'friend_varia': 'NA', 'friend_without_description': 'NA', 'friend_local': 'NA',\n",
      "                          'friend_without_place': 'NA', 'friend_other_place': 'NA'}\n",
      "        \n",
      "        friendsDic['friend_librarian'] = cluster['librarian']\n",
      "        friendsDic['friend_library'] = cluster['Bib']\n",
      "        friendsDic['friend_publisher'] = cluster['publisher']\n",
      "        friendsDic['friend_varia'] = cluster['varia']\n",
      "        friendsDic['friend_without_description'] = cluster['--']\n",
      "        friendsDic['friend_local'] = location['local']\n",
      "        friendsDic['friend_without_place'] = location['--']\n",
      "        friendsDic['friend_other_place'] = len(friends) - (friendsDic['friend_local'] + friendsDic['friend_without_place'])\n",
      "        e.update(friendsDic)                        # update the dictionary e\n",
      "    \n",
      "    \n",
      "        # 4. follower file offnen\n",
      "        followersFileName = sn + '_Followers_' + datestampFriends + '.csv'\n",
      "        followers = impCSV(followersFileName)\n",
      "        dFol = {}\n",
      "        from collections import Counter\n",
      "        LoClusterFol = []\n",
      "        LoLocationFol = []\n",
      "        for i in followers:\n",
      "            LoClusterFol.append(i['cluster'])\n",
      "            LoLocationFol.append(i['followers_location'])\n",
      "        clusterFol = Counter(LoClusterFol)  \n",
      "        locationFol = Counter(LoLocationFol)\n",
      "        dFol['follower_librarian'] = clusterFol['librarian']\n",
      "        dFol['follower_library'] = clusterFol['Bib']\n",
      "        dFol['follower_publisher'] = clusterFol['publisher']\n",
      "        dFol['follower_varia'] = clusterFol['varia']\n",
      "        dFol['follower_without_description'] = clusterFol['--']\n",
      "        dFol['follower_local'] = locationFol['local']\n",
      "        dFol['follower_without_place'] = locationFol['--']\n",
      "        dFol['follower_other_place'] = len(followers) - (dFol['follower_local'] + dFol['follower_without_place'])    \n",
      "        e.update(dFol)                        # update the dictionary e\n",
      "    \n",
      "        \n",
      "        # 5. open UniBib_timelineStats_2014-04-02.csv\n",
      "        tlfilename = filename[:-26] + '_timelineStats_' + datestampTLS + '.csv'\n",
      "        tlstats = impCSV(tlfilename)\n",
      "        dTLS = {}\n",
      "        \n",
      "        #tweets = 0\n",
      "        isGenuine = 0\n",
      "        \n",
      "        hasMedia = 0\n",
      "        hasURL = 0\n",
      "        hasMention = 0\n",
      "        hasHash = 0\n",
      "        hasEntity = 0\n",
      "        resFac = 0\n",
      "        isFav = 0\n",
      "        isRT = 0\n",
      "        \n",
      "        isReply = 0\n",
      "        repNoOrph = 0\n",
      "        hrs2a = 0\n",
      "        \n",
      "        isAuto = 0\n",
      "        \n",
      "        for ix in tlstats:\n",
      "            if ix['screen_name'].lower() == sn.lower():\n",
      "                #tweets += 1\n",
      "                if int(ix['genuine_tweet']) == 1:      # all the following stats shall only be calculated\n",
      "                    isGenuine += 1                     # for the genuine tweets of the library\n",
      "                    hasMedia += int(ix['has_media'])\n",
      "                    hasURL += int(ix['has_url'])\n",
      "                    hasMention += int(ix['has_mention'])\n",
      "                    hasHash += int(ix['has_hashtag'])\n",
      "                    if int(ix['has_media']) + int(ix['has_url']) + int(ix['has_mention']) + int(ix['has_hashtag']) > 0:\n",
      "                        hasEntity += 1\n",
      "                    \n",
      "                    resFac += float(ix['resonance_Factor']) \n",
      "                    \n",
      "                    if int(ix['favorite_count']) > 0:\n",
      "                        isFav += 1\n",
      "                    if int(ix['rt_count']) > 0:\n",
      "                        isRT += 1\n",
      "                    \n",
      "                    if int(ix['is_reply']) == 1:\n",
      "                        isReply += 1\n",
      "                        if int(ix['orphan']) == 0:\n",
      "                            repNoOrph += 1                         # to calculate average of reply time, the\n",
      "                            hrs2a += float(ix['hours_to_answer'])  # orphaned replies can't be taken into account\n",
      "                    \n",
      "                    if int(ix['auto_tweet']) == 1:\n",
      "                        isAuto += 1\n",
      "\n",
      "        if repNoOrph == 0:\n",
      "            dTLS['avg_hours_to_answer'] = 0\n",
      "        else:\n",
      "            dTLS['avg_hours_to_answer'] = round(float(hrs2a)/repNoOrph,2)\n",
      "                \n",
      "        if isGenuine > 0:        \n",
      "            dTLS['genuine_tweet_ratio'] = round(float(isGenuine)/tweets,2)   \n",
      "            dTLS['avg_has_media'] = round(float(hasMedia)/isGenuine,2)\n",
      "            dTLS['avg_has_url'] = round(float(hasURL)/isGenuine,2)\n",
      "            dTLS['avg_has_mention'] = round(float(hasMention)/isGenuine,2)\n",
      "            dTLS['avg_has_hashtag'] = round(float(hasHash)/isGenuine,2)\n",
      "            dTLS['avg_has_entity'] = round(float(hasEntity)/isGenuine,2)\n",
      "            dTLS['avg_resonanceFactor'] = round(float(resFac)/isGenuine,2)\n",
      "            dTLS['avg_Favs'] = round(float(isFav)/isGenuine,2)\n",
      "            dTLS['avg_RTs'] = round(float(isRT)/isGenuine,2)        \n",
      "            dTLS['replies_ratio'] = round(float(isReply)/isGenuine,2)\n",
      "            dTLS['auto_tweet_ratio'] = round(float(isAuto)/tweets,2)\n",
      "        else:\n",
      "            dTLS['genuine_tweet_ratio'] = 0.0  \n",
      "            dTLS['avg_has_media'] = 'NA'\n",
      "            dTLS['avg_has_url'] = 'NA'\n",
      "            dTLS['avg_has_mention'] = 'NA'\n",
      "            dTLS['avg_has_hashtag'] = 'NA'\n",
      "            dTLS['avg_has_entity'] = 'NA'\n",
      "            dTLS['avg_resonanceFactor'] = 'NA'\n",
      "            dTLS['avg_Favs'] = 'NA'\n",
      "            dTLS['avg_RTs'] = 'NA'       \n",
      "            dTLS['replies_ratio'] = 'NA'\n",
      "            dTLS['auto_tweet_ratio'] = 'NA'\n",
      "\n",
      "        e.update(dTLS)                        # update the dictionary e\n",
      "             \n",
      "        # append the List of Dictionaries with the new dictionary\n",
      "        LoD.append(e)\n",
      "    \n",
      "    import datetime\n",
      "    datestamp = datetime.datetime.now().strftime('%Y-%m-%d')    \n",
      "    libTwitterStatsFilename = filename[:-26] + '_libTwitterStats_' + datestamp + '.csv'\n",
      "    exp2CSV(LoD, libTwitterStatsFilename)\n",
      "    print \"The summary was saved as \" + libTwitterStatsFilename + \".\"\n",
      "    return LoD\n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Function Calls"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "NatBib = libTwitterStats('NatBib_BasicStats_2014-04-07.csv', '2014-04-06','2014-04-07','2014-04-09')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of libraries: 3\n",
        "The summary was saved as NatBib_libTwitterStats_2014-04-09.csv."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "UniBib = libTwitterStats('UniBib_BasicStats_2014-04-07.csv', '2014-04-06','2014-04-06','2014-04-09')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of libraries: 27\n",
        "The summary was saved as UniBib_libTwitterStats_2014-04-09.csv."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "OeBib = libTwitterStats('OeBib_BasicStats_2014-04-07.csv', '2014-04-06','2014-04-06','2014-04-09')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of libraries: 21\n",
        "The summary was saved as OeBib_libTwitterStats_2014-04-09.csv."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}